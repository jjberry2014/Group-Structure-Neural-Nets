{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/Volumes/data/LosAlamosSummer')\n",
    "sys.path.insert(0, '/Volumes/data/LosAlamosSummer/DrOsborneCode')\n",
    "\n",
    "import Utilities as ut\n",
    "import importlib\n",
    "import model as mod\n",
    "import predict_with_uncertainty as pu\n",
    "import custom as cus\n",
    "importlib.reload(ut)\n",
    "importlib.reload(mod)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(cus)\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Sphere           LWR           SFR\n",
      "0     2.615712e+02  1.000000e-03  1.000000e-03\n",
      "1     5.737464e+02  6.865624e-03  6.865624e-03\n",
      "2     8.888122e+02  9.160728e-03  9.160728e-03\n",
      "3     1.195336e+03  1.107134e-02  1.107134e-02\n",
      "4     1.481597e+03  1.273122e-02  1.273122e-02\n",
      "...            ...           ...           ...\n",
      "997   4.267269e+06  7.188363e+06  7.188363e+06\n",
      "998   4.568146e+06  7.556836e+06  7.556836e+06\n",
      "999   4.976225e+06  8.021766e+06  8.021766e+06\n",
      "1000  5.607251e+06  8.701618e+06  8.701618e+06\n",
      "1001  7.020693e+06           NaN           NaN\n",
      "\n",
      "[1002 rows x 3 columns]\n",
      "0       1.000000e-03\n",
      "1       6.865624e-03\n",
      "2       9.160728e-03\n",
      "3       1.107134e-02\n",
      "4       1.273122e-02\n",
      "            ...     \n",
      "997     7.188363e+06\n",
      "998     7.556836e+06\n",
      "999     8.021766e+06\n",
      "1000    8.701618e+06\n",
      "1001             NaN\n",
      "Name: LWR, Length: 1002, dtype: float64\n",
      "[1.00000000e-03 6.86562376e-03 9.16072825e-03 ... 7.55683605e+06\n",
      " 8.02176620e+06 8.70161772e+06]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel ('/Volumes/data/LosAlamosSummer/Serializationstructures.xlsx')\n",
    "print (df)\n",
    "print(df.LWR)\n",
    "SS=np.array(df.LWR[:-1])\n",
    "print(SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading In Data\n",
      "Finished Loading Data\n"
     ]
    }
   ],
   "source": [
    "#datapath = '/Users/jessiejo/data/VBUDS/GroupStructurePaper/NeuralNetworks/All_Libraries/NewDataSetFull1.mat'\n",
    "datapath='/Volumes/data/LosAlamosSummer/LWR/DATA/LWR_data_7.mat'\n",
    "print('Loading In Data')\n",
    "kinfBOL,kinfMOL,kinfEOL,GS=ut.LoadData(datapath,1)\n",
    "#MakeGroupDensity(X, nDecades)\n",
    "Nfeatures = 1000;\n",
    "allData= ut.ProcessData(datapath, 1,1000,1,SS,1)\n",
    "# allData: (100,000x1,000) y_direct: (100,000x3)\n",
    "print('Finished Loading Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49999,)\n",
      "49999\n",
      "(49999, 3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q -U keras-tuner\n",
    "print(kinfBOL.shape)\n",
    "print(len(kinfBOL))\n",
    "kinf=np.array(np.zeros((len(kinfBOL),3)))\n",
    "kinf[:,0]=kinfBOL\n",
    "kinf[:,1]=kinfMOL\n",
    "kinf[:,2]=kinfEOL#np.concatenate((kinfBOL,kinfMOL,kinfEOL),axis=0)\n",
    "print(kinf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 9999)\n",
      "(3, 4999)\n",
      "(49999, 3)\n",
      "(3, 34999)\n"
     ]
    }
   ],
   "source": [
    "Nsamples,Ndecades = allData.shape\n",
    "vldF=.1\n",
    "testF=.2\n",
    "normConst=1#np.linalg.norm(kinf)\n",
    "y_norm=np.array(kinf/normConst)\n",
    "\n",
    "X, X_test, y, y_test, vldF_corr = ut.makeFractions(Nsamples, vldF, testF, allData, y_norm, 1)\n",
    "\n",
    "\n",
    "NtrainingSamples = int(Nsamples*(1 - testF))\n",
    "tranValSplit=int(NtrainingSamples*(1-vldF_corr))\n",
    "X_train=X[:tranValSplit,:]\n",
    "y_train=y[:,:tranValSplit]\n",
    "X_val=X[tranValSplit+1:,:]\n",
    "y_val=y[:,tranValSplit+1:]\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n",
    "print(y_norm.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 205)               205205    \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 328)               67568     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 987       \n",
      "=================================================================\n",
      "Total params: 273,760\n",
      "Trainable params: 273,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=134\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(205, activation='elu', name='hidden_1', input_dim=1000),\n",
    "    layers.Dense(328, activation='elu',  name='hidden_2'),\n",
    "    layers.Dense(3, activation='linear',name='output')])\n",
    "model.compile(loss=\"mean_squared_logarithmic_error\",metrics=\"mean_squared_logarithmic_error\")\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.1640 - val_loss: 0.1263\n",
      "Epoch 2/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0788 - val_loss: 0.0654\n",
      "Epoch 3/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0510 - val_loss: 0.0498\n",
      "Epoch 4/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0399 - val_loss: 0.0369\n",
      "Epoch 5/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0365 - val_loss: 0.0319\n",
      "Epoch 6/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0323 - val_loss: 0.0343\n",
      "Epoch 7/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0295\n",
      "Epoch 8/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0294 - val_loss: 0.0353\n",
      "Epoch 9/800\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0282\n",
      "Epoch 10/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0272 - val_loss: 0.0295\n",
      "Epoch 11/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0267\n",
      "Epoch 12/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0259 - val_loss: 0.0294\n",
      "Epoch 13/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0246 - val_loss: 0.0251\n",
      "Epoch 14/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0241 - val_loss: 0.0305\n",
      "Epoch 15/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0257\n",
      "Epoch 16/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0253\n",
      "Epoch 17/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0237\n",
      "Epoch 18/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0261\n",
      "Epoch 19/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0206 - val_loss: 0.0221\n",
      "Epoch 20/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0240\n",
      "Epoch 21/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0199 - val_loss: 0.0221\n",
      "Epoch 22/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0190 - val_loss: 0.0227\n",
      "Epoch 23/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0236\n",
      "Epoch 24/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0223\n",
      "Epoch 25/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0234\n",
      "Epoch 26/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0244\n",
      "Epoch 27/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0230\n",
      "Epoch 28/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 29/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0253\n",
      "Epoch 30/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0209\n",
      "Epoch 31/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0221\n",
      "Epoch 32/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0212\n",
      "Epoch 33/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0225\n",
      "Epoch 34/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0215\n",
      "Epoch 35/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0197\n",
      "Epoch 36/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0217\n",
      "Epoch 37/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0204\n",
      "Epoch 38/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0211\n",
      "Epoch 39/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0193\n",
      "Epoch 40/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0192\n",
      "Epoch 41/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0193\n",
      "Epoch 42/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0207\n",
      "Epoch 43/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0199\n",
      "Epoch 44/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0191\n",
      "Epoch 45/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0190\n",
      "Epoch 46/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0212\n",
      "Epoch 47/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0185\n",
      "Epoch 48/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0198\n",
      "Epoch 49/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0183\n",
      "Epoch 50/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0194\n",
      "Epoch 51/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0178\n",
      "Epoch 52/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0184\n",
      "Epoch 53/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0199\n",
      "Epoch 54/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0177\n",
      "Epoch 55/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0194\n",
      "Epoch 56/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0186\n",
      "Epoch 57/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0193\n",
      "Epoch 58/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 59/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0181\n",
      "Epoch 60/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0187\n",
      "Epoch 61/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0175\n",
      "Epoch 62/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0197\n",
      "Epoch 63/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0182\n",
      "Epoch 64/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0180\n",
      "Epoch 65/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0221\n",
      "Epoch 66/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0172\n",
      "Epoch 67/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0168\n",
      "Epoch 68/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0177\n",
      "Epoch 69/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0181\n",
      "Epoch 70/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0186\n",
      "Epoch 71/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0192\n",
      "Epoch 72/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0220\n",
      "Epoch 73/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0160\n",
      "Epoch 74/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0172\n",
      "Epoch 75/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0164\n",
      "Epoch 76/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0181\n",
      "Epoch 77/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 78/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0187\n",
      "Epoch 79/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0185\n",
      "Epoch 80/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0168\n",
      "Epoch 81/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0082 - val_loss: 0.0168\n",
      "Epoch 82/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0159\n",
      "Epoch 83/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0159\n",
      "Epoch 84/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0156\n",
      "Epoch 85/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0159\n",
      "Epoch 86/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0167\n",
      "Epoch 87/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0152\n",
      "Epoch 88/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0154\n",
      "Epoch 89/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0169\n",
      "Epoch 90/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0181\n",
      "Epoch 91/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0164\n",
      "Epoch 92/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0156\n",
      "Epoch 93/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0163\n",
      "Epoch 94/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0151\n",
      "Epoch 95/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0150\n",
      "Epoch 96/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0162\n",
      "Epoch 97/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0165\n",
      "Epoch 98/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0162\n",
      "Epoch 99/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0170\n",
      "Epoch 100/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0148\n",
      "Epoch 101/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0149\n",
      "Epoch 102/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0161\n",
      "Epoch 103/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0173\n",
      "Epoch 104/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0147\n",
      "Epoch 105/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0072 - val_loss: 0.0154\n",
      "Epoch 106/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0153\n",
      "Epoch 107/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0150\n",
      "Epoch 108/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0155\n",
      "Epoch 109/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0148\n",
      "Epoch 110/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0142\n",
      "Epoch 111/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0153\n",
      "Epoch 112/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0143\n",
      "Epoch 113/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0148\n",
      "Epoch 114/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0146\n",
      "Epoch 115/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0147\n",
      "Epoch 116/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0062 - val_loss: 0.0146\n",
      "Epoch 117/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0138\n",
      "Epoch 118/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0147\n",
      "Epoch 119/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0156\n",
      "Epoch 120/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0150\n",
      "Epoch 121/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0062 - val_loss: 0.0154\n",
      "Epoch 122/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 123/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0152\n",
      "Epoch 124/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0149\n",
      "Epoch 125/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0145\n",
      "Epoch 126/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0141\n",
      "Epoch 127/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0134\n",
      "Epoch 128/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0160\n",
      "Epoch 129/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0137\n",
      "Epoch 130/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0141\n",
      "Epoch 131/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0135\n",
      "Epoch 132/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0147\n",
      "Epoch 133/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0154\n",
      "Epoch 134/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0137\n",
      "Epoch 135/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0057 - val_loss: 0.0132\n",
      "Epoch 136/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0133\n",
      "Epoch 137/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0139\n",
      "Epoch 138/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0140\n",
      "Epoch 139/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0132\n",
      "Epoch 140/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0053 - val_loss: 0.0131\n",
      "Epoch 141/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0061 - val_loss: 0.0139\n",
      "Epoch 142/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0059 - val_loss: 0.0141\n",
      "Epoch 143/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0141\n",
      "Epoch 144/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0134\n",
      "Epoch 145/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0059 - val_loss: 0.0142\n",
      "Epoch 146/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0055 - val_loss: 0.0132\n",
      "Epoch 147/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0058 - val_loss: 0.0152\n",
      "Epoch 148/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0133\n",
      "Epoch 149/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0151\n",
      "Epoch 150/800\n",
      "259/262 [============================>.] - ETA: 0s - loss: 0.0054Restoring model weights from the end of the best epoch.\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0054 - val_loss: 0.0143\n",
      "Epoch 00150: early stopping\n",
      "Epoch 1/800\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 0.0035 - val_loss: 0.0127\n",
      "Epoch 2/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0029 - val_loss: 0.0126\n",
      "Epoch 3/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0127\n",
      "Epoch 4/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0024 - val_loss: 0.0126\n",
      "Epoch 5/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0023 - val_loss: 0.0126\n",
      "Epoch 6/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0021 - val_loss: 0.0126\n",
      "Epoch 7/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0021 - val_loss: 0.0126\n",
      "Epoch 8/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0020 - val_loss: 0.0126\n",
      "Epoch 9/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0019 - val_loss: 0.0126\n",
      "Epoch 10/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0019 - val_loss: 0.0126\n",
      "Epoch 11/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0126\n",
      "Epoch 12/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0126\n",
      "Epoch 13/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0126\n",
      "Epoch 14/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0127\n",
      "Epoch 15/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0126\n",
      "Epoch 16/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 17/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 18/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0017 - val_loss: 0.0127\n",
      "Epoch 19/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 20/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 21/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 22/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 23/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 24/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 25/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0127\n",
      "Epoch 26/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 27/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 28/800\n",
      "251/262 [===========================>..] - ETA: 0s - loss: 0.0015Restoring model weights from the end of the best epoch.\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 00028: early stopping\n",
      "Epoch 1/800\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0125\n",
      "Epoch 2/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 3/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 4/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 5/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 6/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 7/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 8/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 9/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 10/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 11/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 12/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 13/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 14/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 15/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 16/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 17/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 18/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 19/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 20/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 21/800\n",
      "258/262 [============================>.] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch.\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 00021: early stopping\n",
      "Epoch 1/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 2/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 3/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 4/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 5/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 6/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 7/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 8/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 9/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 10/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 11/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 12/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 13/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 14/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 15/800\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 16/800\n",
      "248/262 [===========================>..] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch.\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0125\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181b72460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-6))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011236523"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "metric = tf.keras.metrics.MeanSquaredError(name=\"mean_average_error\", dtype=None)\n",
    "metric.update_state(np.array(y_predicted*normConst),np.array(y_test.T*normConst))\n",
    "metric.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating dataset\n",
    "a = (y_predicted-y_test.T)\n",
    "print(a.shape)\n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a[:,2],bins=500,alpha=0.75,label=\"EOL\",color='r')\n",
    "ax.hist(a[:,1],bins=500,alpha=0.25,label=\"MOL\",color='b')\n",
    "ax.hist(a[:,0],bins=500,alpha=0.25,label=\"BOL\",color='g')\n",
    "plt.xlabel(\"$Δk_{\\infty}$\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.title(\"LWR $Δk_{\\infty}$, flux based serialization\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([-0.5,0.5])\n",
    "plt.ylim([0,1000])\n",
    "\n",
    "plt.savefig(\"PICS/LWR_deltaK_shaped.png\",bbox_inches =\"tight\",\n",
    "            pad_inches = 1,\n",
    "            transparent = False,\n",
    "            facecolor =\"w\",\n",
    "            edgecolor ='w',\n",
    "            orientation ='landscape')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    " \n",
    "\n",
    "n_bins = 500\n",
    " \n",
    "\n",
    "# Creating histogram\n",
    "fig, axs = plt.subplots(figsize =(10, 7))\n",
    " \n",
    "axs.hist(y_test.T[:,0], bins = n_bins,label=\"BOL actual\")\n",
    "axs.hist(y_predicted[:,0], bins = n_bins,label=\"BOL predicted\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"$k_{\\infty}$\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title(\"LWR $k_{\\infty}$, shaped serialization\")\n",
    "plt.savefig(\"PICS/kinfPredDist_shaped.png\",bbox_inches =\"tight\",\n",
    "            pad_inches = 1,\n",
    "            transparent = False,\n",
    "            facecolor =\"w\",\n",
    "            edgecolor ='w',\n",
    "            orientation ='landscape')\n",
    "\n",
    "plt.show()\n",
    "# Show plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035965005992451955\n",
      "0.03406690454516413\n",
      "0.03026876187655921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.std(a[:,0]))\n",
    "print(np.std(a[:,1]))\n",
    "print(np.std(a[:,2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
