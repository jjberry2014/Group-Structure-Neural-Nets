{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/Volumes/data/LosAlamosSummer')\n",
    "sys.path.insert(0, '/Volumes/data/LosAlamosSummer/DrOsborneCode')\n",
    "\n",
    "import Utilities as ut\n",
    "import importlib\n",
    "import model as mod\n",
    "import predict_with_uncertainty as pu\n",
    "import custom as cus\n",
    "importlib.reload(ut)\n",
    "importlib.reload(mod)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(cus)\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading In Data\n",
      "Finished Loading Data\n"
     ]
    }
   ],
   "source": [
    "#datapath = '/Users/jessiejo/data/VBUDS/GroupStructurePaper/NeuralNetworks/All_Libraries/NewDataSetFull1.mat'\n",
    "datapath='/Volumes/data/LosAlamosSummer/SFR/DATA/SFR_data_8.mat'\n",
    "print('Loading In Data')\n",
    "kinfBOL,kinfMOL,kinfEOL,GS=ut.LoadData(datapath,1)\n",
    "#MakeGroupDensity(X, nDecades)\n",
    "Nfeatures = 1000;\n",
    "allData= ut.ProcessData(datapath, 1,1000,0,0,1)\n",
    "# allData: (100,000x1,000) y_direct: (100,000x3)\n",
    "print('Finished Loading Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data loads raw data from the .mat file\n",
    "Inputs\n",
    "datapath: Path to .mat file containing the data [string]\n",
    "BU: whether the data contains burnup; 1=burnup, 0=no burnup [bool]\n",
    "\n",
    "ProcessData is the serialization maker \n",
    "Inputs\n",
    "datapath: Path to .mat file containing the data [string]\n",
    "Percent of data to be used: in most cases full data set will be used but good for analysis [double](0-1)\n",
    "ndecades: Number of decades wanted in equal lethargy serialization. Number is ignored if custom serialization inputted [int]\n",
    "mode: equal lethargy mode (0) or custom serialization mode (1) [boolean]\n",
    "input serial: a custom serialization regime (ignored if mode is not 1) [numpy array]\n",
    "BU: whether the data contains burnup; 1=burnup, 0=no burnup [bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "50000\n",
      "(50000, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!pip install -q -U keras-tuner\n",
    "print(kinfBOL.shape)\n",
    "print(len(kinfBOL))\n",
    "kinf=np.array(np.zeros((len(kinfBOL),3)))\n",
    "kinf[:,0]=kinfBOL\n",
    "kinf[:,1]=kinfMOL\n",
    "kinf[:,2]=kinfEOL#np.concatenate((kinfBOL,kinfMOL,kinfEOL),axis=0)\n",
    "print(kinf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 9999)\n",
      "(3, 4999)\n",
      "(50000, 3)\n",
      "(3, 35000)\n"
     ]
    }
   ],
   "source": [
    "Nsamples,Ndecades = allData.shape\n",
    "vldF=.1\n",
    "testF=.2\n",
    "normConst=1#np.linalg.norm(kinf)\n",
    "y_norm=np.array(kinf/normConst)\n",
    "\n",
    "X, X_test, y, y_test, vldF_corr = ut.makeFractions(Nsamples, vldF, testF, allData, y_norm, 1)\n",
    "\n",
    "\n",
    "NtrainingSamples = int(Nsamples*(1 - testF))\n",
    "tranValSplit=int(NtrainingSamples*(1-vldF_corr))\n",
    "X_train=X[:tranValSplit,:]\n",
    "y_train=y[:,:tranValSplit]\n",
    "X_val=X[tranValSplit+1:,:]\n",
    "y_val=y[:,tranValSplit+1:]\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n",
    "print(y_norm.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "makeFractions splits the data into appropriatly sized sets\n",
    "Nsamples is the number of samples of the data set\n",
    "vldF is the validation fraction\n",
    "testF is the test fraction\n",
    "allData is the set of serialzed group structures\n",
    "y_norm is the kinfs that correspond to the serialized group structures (normalized or otherwise)\n",
    "BU (the last input) is a boolean determining whether the data contains burnup [Boolean] (used in the same manner as previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 48)                48000     \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 746)               36554     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 2241      \n",
      "=================================================================\n",
      "Total params: 86,795\n",
      "Trainable params: 86,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=116\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(48, activation='elu', name='hidden_1', input_dim=999),\n",
    "    layers.Dense(746, activation='elu',  name='hidden_2'),\n",
    "    layers.Dense(3, activation='linear',name='output')])\n",
    "model.compile(loss=\"mean_squared_logarithmic_error\",metrics=\"mean_squared_logarithmic_error\")\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.1115 - val_loss: 0.0473\n",
      "Epoch 2/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0471 - val_loss: 0.0419\n",
      "Epoch 3/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0429 - val_loss: 0.0459\n",
      "Epoch 4/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0383\n",
      "Epoch 5/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0386\n",
      "Epoch 6/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0367\n",
      "Epoch 7/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0377 - val_loss: 0.0370\n",
      "Epoch 8/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0365\n",
      "Epoch 9/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0381\n",
      "Epoch 10/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 11/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0423\n",
      "Epoch 12/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0390\n",
      "Epoch 13/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0361\n",
      "Epoch 14/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.0362\n",
      "Epoch 15/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.0380\n",
      "Epoch 16/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0356\n",
      "Epoch 17/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0332\n",
      "Epoch 18/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0293 - val_loss: 0.0303\n",
      "Epoch 19/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0264 - val_loss: 0.0296\n",
      "Epoch 20/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0260\n",
      "Epoch 21/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0230 - val_loss: 0.0253\n",
      "Epoch 22/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0314\n",
      "Epoch 23/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0217 - val_loss: 0.0248\n",
      "Epoch 24/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0216\n",
      "Epoch 25/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0198 - val_loss: 0.0226\n",
      "Epoch 26/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0234\n",
      "Epoch 27/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0219\n",
      "Epoch 28/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0222\n",
      "Epoch 29/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 30/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 31/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0164 - val_loss: 0.0200\n",
      "Epoch 32/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0163 - val_loss: 0.0208\n",
      "Epoch 33/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0200\n",
      "Epoch 34/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0212\n",
      "Epoch 35/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0208\n",
      "Epoch 36/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0200\n",
      "Epoch 37/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0208\n",
      "Epoch 38/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0135 - val_loss: 0.0174\n",
      "Epoch 39/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0183\n",
      "Epoch 40/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0173\n",
      "Epoch 41/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0171\n",
      "Epoch 42/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0170\n",
      "Epoch 43/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0178\n",
      "Epoch 44/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0116 - val_loss: 0.0199\n",
      "Epoch 45/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0171\n",
      "Epoch 46/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0168\n",
      "Epoch 47/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0177\n",
      "Epoch 48/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0166\n",
      "Epoch 49/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0158\n",
      "Epoch 50/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0169\n",
      "Epoch 51/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0157\n",
      "Epoch 52/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0100 - val_loss: 0.0151\n",
      "Epoch 53/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0156\n",
      "Epoch 54/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0168\n",
      "Epoch 55/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0151\n",
      "Epoch 56/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0151\n",
      "Epoch 57/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0163\n",
      "Epoch 58/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0167\n",
      "Epoch 59/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0165\n",
      "Epoch 60/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0144\n",
      "Epoch 61/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0157\n",
      "Epoch 62/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0148\n",
      "Epoch 63/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0148\n",
      "Epoch 64/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0141\n",
      "Epoch 65/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0165\n",
      "Epoch 66/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0145\n",
      "Epoch 67/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0144\n",
      "Epoch 68/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0143\n",
      "Epoch 69/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0145\n",
      "Epoch 70/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0152\n",
      "Epoch 71/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0144\n",
      "Epoch 72/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 73/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 74/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0160\n",
      "Epoch 75/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0148\n",
      "Epoch 76/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0143\n",
      "Epoch 77/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0140\n",
      "Epoch 78/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0137\n",
      "Epoch 79/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0141\n",
      "Epoch 80/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0154\n",
      "Epoch 81/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.0137\n",
      "Epoch 82/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0171\n",
      "Epoch 83/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0137\n",
      "Epoch 84/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0136\n",
      "Epoch 85/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0146\n",
      "Epoch 86/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0138\n",
      "Epoch 87/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0136\n",
      "Epoch 88/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0135\n",
      "Epoch 89/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0135\n",
      "Epoch 90/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0137\n",
      "Epoch 91/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0060 - val_loss: 0.0148\n",
      "Epoch 92/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0135\n",
      "Epoch 93/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0133\n",
      "Epoch 94/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0136\n",
      "Epoch 95/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0137\n",
      "Epoch 96/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0134\n",
      "Epoch 97/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0138\n",
      "Epoch 98/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0137\n",
      "Epoch 99/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0134\n",
      "Epoch 100/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0060 - val_loss: 0.0143\n",
      "Epoch 101/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0134\n",
      "Epoch 102/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0133\n",
      "Epoch 103/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0143\n",
      "Epoch 104/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0137\n",
      "Epoch 105/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0140\n",
      "Epoch 106/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0133\n",
      "Epoch 107/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0137\n",
      "Epoch 108/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0135\n",
      "Epoch 109/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0132\n",
      "Epoch 110/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0137\n",
      "Epoch 111/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0133\n",
      "Epoch 112/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0056 - val_loss: 0.0132\n",
      "Epoch 113/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0145\n",
      "Epoch 114/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0132\n",
      "Epoch 115/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0161\n",
      "Epoch 116/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0132\n",
      "Epoch 117/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0146\n",
      "Epoch 118/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0134\n",
      "Epoch 119/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0134\n",
      "Epoch 120/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0133\n",
      "Epoch 121/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0132\n",
      "Epoch 122/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0145\n",
      "Epoch 123/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0133\n",
      "Epoch 124/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0135\n",
      "Epoch 125/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0136\n",
      "Epoch 126/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0135\n",
      "Epoch 127/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0133\n",
      "Epoch 128/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0133\n",
      "Epoch 129/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0140\n",
      "Epoch 130/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0140\n",
      "Epoch 131/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0050 - val_loss: 0.0131\n",
      "Epoch 132/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0132\n",
      "Epoch 133/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 134/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0135\n",
      "Epoch 135/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0129\n",
      "Epoch 136/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0135\n",
      "Epoch 137/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0130\n",
      "Epoch 138/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0131\n",
      "Epoch 139/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0132\n",
      "Epoch 140/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0132\n",
      "Epoch 141/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0137\n",
      "Epoch 142/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0130\n",
      "Epoch 143/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0132\n",
      "Epoch 144/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0131\n",
      "Epoch 145/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 146/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0137\n",
      "Epoch 147/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0131\n",
      "Epoch 148/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0132\n",
      "Epoch 149/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0133\n",
      "Epoch 150/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0129\n",
      "Epoch 151/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0132\n",
      "Epoch 152/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 153/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0137\n",
      "Epoch 154/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0129\n",
      "Epoch 155/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0130\n",
      "Epoch 156/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0129\n",
      "Epoch 157/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0130\n",
      "Epoch 158/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 159/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0129\n",
      "Epoch 160/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 162/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0130\n",
      "Epoch 163/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 164/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0127\n",
      "Epoch 165/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0128\n",
      "Epoch 166/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0131\n",
      "Epoch 167/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 168/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0130\n",
      "Epoch 169/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0128\n",
      "Epoch 170/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0129\n",
      "Epoch 171/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0128\n",
      "Epoch 172/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0127\n",
      "Epoch 173/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0129\n",
      "Epoch 174/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0129\n",
      "Epoch 175/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0128\n",
      "Epoch 176/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0129\n",
      "Epoch 177/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0135\n",
      "Epoch 178/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0128\n",
      "Epoch 179/800\n",
      "269/302 [=========================>....] - ETA: 0s - loss: 0.0045Restoring model weights from the end of the best epoch.\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 00179: early stopping\n",
      "Epoch 1/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0030 - val_loss: 0.0125\n",
      "Epoch 2/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0125\n",
      "Epoch 3/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0124\n",
      "Epoch 4/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0124\n",
      "Epoch 5/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0125\n",
      "Epoch 6/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0125\n",
      "Epoch 7/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 8/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 9/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 0.0125\n",
      "Epoch 10/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0125\n",
      "Epoch 11/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0125\n",
      "Epoch 12/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 13/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 14/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 15/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 16/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 17/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 18/800\n",
      "279/302 [==========================>...] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch.\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 00018: early stopping\n",
      "Epoch 1/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0124\n",
      "Epoch 2/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 3/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 4/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 5/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 6/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 7/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0124\n",
      "Epoch 8/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0124\n",
      "Epoch 9/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0124\n",
      "Epoch 10/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0124\n",
      "Epoch 11/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 12/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 13/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0124\n",
      "Epoch 14/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 0.0124\n",
      "Epoch 15/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 0.0125\n",
      "Epoch 16/800\n",
      "270/302 [=========================>....] - ETA: 0s - loss: 0.0016Restoring model weights from the end of the best epoch.\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 0.0124\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 2/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 3/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 4/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 5/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 6/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 7/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 8/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 9/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 10/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 11/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 12/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 13/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 14/800\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 15/800\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 16/800\n",
      "269/302 [=========================>....] - ETA: 0s - loss: 0.0018Restoring model weights from the end of the best epoch.\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0124\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15b71bd60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-6))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004276048\n",
      "[[1.9311227 1.8704611 1.7803249]\n",
      " [1.953152  1.8958334 1.8089652]\n",
      " [1.9383469 1.8804944 1.7962253]\n",
      " ...\n",
      " [1.9250858 1.8689259 1.7796767]\n",
      " [1.8715037 1.8099027 1.7199602]\n",
      " [1.9177428 1.8542681 1.761034 ]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "metric = tf.keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None)\n",
    "metric.update_state(np.array(y_predicted*normConst),np.array(y_test.T*normConst))\n",
    "print(metric.result().numpy())\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating dataset\n",
    "a = (y_predicted-y_test.T)\n",
    "print(a.shape)\n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a[:,2],bins=500,alpha=0.75,label=\"EOL\",color='r')\n",
    "ax.hist(a[:,1],bins=500,alpha=0.25,label=\"MOL\",color='b')\n",
    "ax.hist(a[:,0],bins=500,alpha=0.25,label=\"BOL\",color='g')\n",
    "plt.xlabel(\"$Δk_{\\infty}$\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.title(\"LWR $Δk_{\\infty}$, eq leth serialization\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([-0.5,0.5])\n",
    "plt.ylim([0,1000])\n",
    "\n",
    "plt.savefig(\"PICS/SFR_deltaK_eqleth.png\",bbox_inches =\"tight\",\n",
    "            pad_inches = 1,\n",
    "            transparent = False,\n",
    "            facecolor =\"w\",\n",
    "            edgecolor ='w',\n",
    "            orientation ='landscape')\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16186506663871794\n",
      "0.020320436379274578\n",
      "0.16571913677010885\n",
      "0.02063347075552276\n",
      "0.16685606944661246\n",
      "0.021022517965701835\n"
     ]
    }
   ],
   "source": [
    "print(np.std(X_test[:,0]))\n",
    "print(np.std(a[:,0]))\n",
    "print(np.std(X_test[:,1]))\n",
    "print(np.std(a[:,1]))\n",
    "print(np.std(X_test[:,2]))\n",
    "print(np.std(a[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9311227 1.953152  1.9383469 ... 1.9250858 1.8715037 1.9177428]\n",
      "(9999, 3)\n",
      "(3, 9999)\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted[:,0])\n",
    "print(y_predicted.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    " \n",
    "\n",
    "n_bins = 500\n",
    " \n",
    "\n",
    "# Creating histogram\n",
    "fig, axs = plt.subplots(figsize =(10, 7))\n",
    " \n",
    "axs.hist(y_test.T[:,0], bins = n_bins,label=\"BOL actual\")\n",
    "axs.hist(y_predicted[:,0], bins = n_bins,label=\"BOL predicted\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"$k_{\\infty}$\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title(\"SFR $k_{\\infty}$, eq leth serialization\")\n",
    "plt.savefig(\"PICS/kinfPredDist_eqleth.png\",bbox_inches =\"tight\",\n",
    "            pad_inches = 1,\n",
    "            transparent = False,\n",
    "            facecolor =\"w\",\n",
    "            edgecolor ='w',\n",
    "            orientation ='landscape')\n",
    "\n",
    "plt.show()\n",
    "# Show plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
