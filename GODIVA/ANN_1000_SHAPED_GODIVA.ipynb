{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Volumes/data/LosAlamosSummer')\n",
    "sys.path.insert(0, '/Volumes/data/LosAlamosSummer/DrOsborneCode')\n",
    "import src.Utilities as ut\n",
    "import importlib\n",
    "import src.models as mod\n",
    "import src.callbacks as cus\n",
    "importlib.reload(ut)\n",
    "importlib.reload(mod)\n",
    "importlib.reload(cus)\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Sphere           LWR           SFR\n",
      "0     2.615712e+02  1.000000e-03  1.000000e-03\n",
      "1     5.737464e+02  6.865624e-03  6.865624e-03\n",
      "2     8.888122e+02  9.160728e-03  9.160728e-03\n",
      "3     1.195336e+03  1.107134e-02  1.107134e-02\n",
      "4     1.481597e+03  1.273122e-02  1.273122e-02\n",
      "...            ...           ...           ...\n",
      "997   4.267269e+06  7.188363e+06  7.188363e+06\n",
      "998   4.568146e+06  7.556836e+06  7.556836e+06\n",
      "999   4.976225e+06  8.021766e+06  8.021766e+06\n",
      "1000  5.607251e+06  8.701618e+06  8.701618e+06\n",
      "1001  7.020693e+06           NaN           NaN\n",
      "\n",
      "[1002 rows x 3 columns]\n",
      "0       2.615712e+02\n",
      "1       5.737464e+02\n",
      "2       8.888122e+02\n",
      "3       1.195336e+03\n",
      "4       1.481597e+03\n",
      "            ...     \n",
      "997     4.267269e+06\n",
      "998     4.568146e+06\n",
      "999     4.976225e+06\n",
      "1000    5.607251e+06\n",
      "1001    7.020693e+06\n",
      "Name: Sphere, Length: 1002, dtype: float64\n",
      "[2.61571245e+02 5.73746435e+02 8.88812185e+02 ... 4.56814626e+06\n",
      " 4.97622490e+06 5.60725104e+06]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel ('/Volumes/data/LosAlamosSummer/Serializationstructures.xlsx')\n",
    "print (df)\n",
    "print(df.Sphere)\n",
    "SS=np.array(df.Sphere[:-1])\n",
    "print(SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading In Data\n",
      "Finished Loading Data\n"
     ]
    }
   ],
   "source": [
    "#datapath = '/Users/jessiejo/data/VBUDS/GroupStructurePaper/NeuralNetworks/All_Libraries/NewDataSetFull1.mat'\n",
    "datapath='/Volumes/data/LosAlamosSummer/GODIVA/GODIVA_data_0_12.mat'\n",
    "print('Loading In Data')\n",
    "kinf,GS=ut.LoadData(datapath,0)\n",
    "#MakeGroupDensity(X, nDecades)\n",
    "Nfeatures = 1000;\n",
    "allData= ut.ProcessData(datapath, 1,1000,1,SS,0)\n",
    "# allData: (100,000x1,000) y_direct: (100,000x3)\n",
    "print('Finished Loading Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "50000\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q -U keras-tuner\n",
    "print(kinf.shape)\n",
    "print(len(kinf))\n",
    "\n",
    "print(kinf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999,)\n",
      "(4999,)\n",
      "(50000,)\n",
      "(35000,)\n"
     ]
    }
   ],
   "source": [
    "Nsamples,Ndecades = allData.shape\n",
    "vldF=.1\n",
    "testF=.2\n",
    "normConst=1#np.linalg.norm(kinf)\n",
    "y_norm=np.array(kinf/normConst)\n",
    "\n",
    "X, X_test, y, y_test, vldF_corr = ut.makeFractions(Nsamples, vldF, testF, allData, y_norm, 0)\n",
    "\n",
    "\n",
    "NtrainingSamples = int(Nsamples*(1 - testF))\n",
    "tranValSplit=int(NtrainingSamples*(1-vldF_corr))\n",
    "X_train=X[:tranValSplit,:]\n",
    "y_train=y[:tranValSplit]\n",
    "X_val=X[tranValSplit+1:,:]\n",
    "y_val=y[tranValSplit+1:]\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n",
    "print(y_norm.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_1 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 2,003,001\n",
      "Trainable params: 2,003,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=500\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(1000, activation='relu', name='hidden_1', input_dim=1000),\n",
    "    layers.Dense(1000, activation='relu',  name='hidden_2'),\n",
    "    layers.Dense(1, activation='linear',name='output')])\n",
    "model.compile(loss=\"mean_squared_logarithmic_error\",metrics=\"mean_squared_logarithmic_error\")\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.1593 - val_loss: 0.0653\n",
      "Epoch 2/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0528 - val_loss: 0.0425\n",
      "Epoch 3/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0449 - val_loss: 0.0404\n",
      "Epoch 4/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0331 - val_loss: 0.0334\n",
      "Epoch 5/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0283 - val_loss: 0.0288\n",
      "Epoch 6/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0225 - val_loss: 0.0281\n",
      "Epoch 7/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0199 - val_loss: 0.0234\n",
      "Epoch 8/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 9/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0147 - val_loss: 0.0170\n",
      "Epoch 10/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 11/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0109 - val_loss: 0.0153\n",
      "Epoch 12/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 13/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 14/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0085 - val_loss: 0.0134\n",
      "Epoch 15/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 16/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0074 - val_loss: 0.0111\n",
      "Epoch 17/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0067 - val_loss: 0.0109\n",
      "Epoch 18/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 19/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0062 - val_loss: 0.0099\n",
      "Epoch 20/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 21/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0060 - val_loss: 0.0106\n",
      "Epoch 22/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 23/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 24/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0055 - val_loss: 0.0093\n",
      "Epoch 25/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 26/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0059 - val_loss: 0.0090\n",
      "Epoch 27/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 28/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0050 - val_loss: 0.0087\n",
      "Epoch 29/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 30/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0047 - val_loss: 0.0090\n",
      "Epoch 31/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0047 - val_loss: 0.0083\n",
      "Epoch 32/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 33/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 34/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 35/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0043 - val_loss: 0.0089\n",
      "Epoch 36/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0042 - val_loss: 0.0077\n",
      "Epoch 37/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 38/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0046 - val_loss: 0.0084\n",
      "Epoch 39/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 40/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 41/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0041 - val_loss: 0.0072\n",
      "Epoch 42/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 43/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 44/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 45/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0040 - val_loss: 0.0072\n",
      "Epoch 46/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0038 - val_loss: 0.0071\n",
      "Epoch 47/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 48/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0037 - val_loss: 0.0074\n",
      "Epoch 49/800\n",
      "70/70 [==============================] - 2s 27ms/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 50/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0037 - val_loss: 0.0066\n",
      "Epoch 51/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 52/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 53/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 54/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0042 - val_loss: 0.0075\n",
      "Epoch 55/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 56/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 57/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 58/800\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 59/800\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 60/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 61/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 62/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0032 - val_loss: 0.0071\n",
      "Epoch 63/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 64/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 65/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 66/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 67/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0033 - val_loss: 0.0063\n",
      "Epoch 68/800\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 69/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 70/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 71/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 72/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 73/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 74/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0034 - val_loss: 0.0089\n",
      "Epoch 75/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 76/800\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 77/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 78/800\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 79/800\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 80/800\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 81/800\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 82/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 83/800\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 84/800\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 85/800\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 86/800\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 87/800\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 88/800\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 89/800\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 90/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 91/800\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 92/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 93/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 94/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 95/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 96/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 97/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 98/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 99/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 100/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 101/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 102/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 103/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 104/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 105/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 106/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 107/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0033 - val_loss: 0.0063\n",
      "Epoch 108/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 109/800\n",
      "70/70 [==============================] - 2s 36ms/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 110/800\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 111/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 112/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 113/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 114/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 115/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 116/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 117/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 118/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 119/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 120/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 121/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 122/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 123/800\n",
      "70/70 [==============================] - 3s 41ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 124/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 125/800\n",
      "70/70 [==============================] - 3s 41ms/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 126/800\n",
      "70/70 [==============================] - 3s 42ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 127/800\n",
      "70/70 [==============================] - 3s 42ms/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 128/800\n",
      "70/70 [==============================] - 3s 42ms/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 129/800\n",
      "70/70 [==============================] - 3s 41ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 130/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 131/800\n",
      "70/70 [==============================] - 3s 46ms/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 132/800\n",
      "70/70 [==============================] - 3s 46ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 133/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 134/800\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 135/800\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 136/800\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 137/800\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 138/800\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 139/800\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 140/800\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 141/800\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 142/800\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 143/800\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 144/800\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 145/800\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 146/800\n",
      "70/70 [==============================] - 4s 50ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 147/800\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 148/800\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 149/800\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 150/800\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 151/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 152/800\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 153/800\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 154/800\n",
      "70/70 [==============================] - 5s 75ms/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 155/800\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 156/800\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 157/800\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 158/800\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 159/800\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 160/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 161/800\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 162/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 3s 45ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 163/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 164/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 165/800\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 166/800\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 167/800\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 168/800\n",
      "70/70 [==============================] - 3s 44ms/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 169/800\n",
      "70/70 [==============================] - 3s 42ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 170/800\n",
      "70/70 [==============================] - 3s 43ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 171/800\n",
      "70/70 [==============================] - 3s 41ms/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 172/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 173/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 174/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 175/800\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0022Restoring model weights from the end of the best epoch.\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 00175: early stopping\n",
      "Epoch 1/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 2/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 3/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 4/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 5/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 6/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 9.8228e-04 - val_loss: 0.0046\n",
      "Epoch 7/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 9.3161e-04 - val_loss: 0.0045\n",
      "Epoch 8/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 9.0019e-04 - val_loss: 0.0046\n",
      "Epoch 9/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 8.5050e-04 - val_loss: 0.0045\n",
      "Epoch 10/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 8.0160e-04 - val_loss: 0.0045\n",
      "Epoch 11/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 8.0710e-04 - val_loss: 0.0045\n",
      "Epoch 12/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 9.1228e-04 - val_loss: 0.0045\n",
      "Epoch 13/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 8.1537e-04 - val_loss: 0.0046\n",
      "Epoch 14/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 7.2864e-04 - val_loss: 0.0045\n",
      "Epoch 15/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 7.2485e-04 - val_loss: 0.0045\n",
      "Epoch 16/800\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 6.9006e-04 - val_loss: 0.0045\n",
      "Epoch 17/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.7050e-04 - val_loss: 0.0045\n",
      "Epoch 18/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.7138e-04 - val_loss: 0.0045\n",
      "Epoch 19/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 6.6363e-04 - val_loss: 0.0046\n",
      "Epoch 20/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.4466e-04 - val_loss: 0.0045\n",
      "Epoch 21/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 6.6380e-04 - val_loss: 0.0046\n",
      "Epoch 22/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.4759e-04 - val_loss: 0.0046\n",
      "Epoch 23/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 8.0595e-04 - val_loss: 0.0046\n",
      "Epoch 24/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.3991e-04 - val_loss: 0.0046\n",
      "Epoch 25/800\n",
      "69/70 [============================>.] - ETA: 0s - loss: 6.2192e-04Restoring model weights from the end of the best epoch.\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 6.2322e-04 - val_loss: 0.0045\n",
      "Epoch 00025: early stopping\n",
      "Epoch 1/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 7.2298e-04 - val_loss: 0.0045\n",
      "Epoch 2/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.8798e-04 - val_loss: 0.0045\n",
      "Epoch 3/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.7728e-04 - val_loss: 0.0045\n",
      "Epoch 4/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 6.6822e-04 - val_loss: 0.0045\n",
      "Epoch 5/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.5957e-04 - val_loss: 0.0045\n",
      "Epoch 6/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.5379e-04 - val_loss: 0.0045\n",
      "Epoch 7/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.4481e-04 - val_loss: 0.0045\n",
      "Epoch 8/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.3957e-04 - val_loss: 0.0045\n",
      "Epoch 9/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.3370e-04 - val_loss: 0.0045\n",
      "Epoch 10/800\n",
      "70/70 [==============================] - 3s 43ms/step - loss: 6.3137e-04 - val_loss: 0.0045\n",
      "Epoch 11/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.2282e-04 - val_loss: 0.0045\n",
      "Epoch 12/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.2032e-04 - val_loss: 0.0045\n",
      "Epoch 13/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.1524e-04 - val_loss: 0.0045\n",
      "Epoch 14/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.0998e-04 - val_loss: 0.0045\n",
      "Epoch 15/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.0532e-04 - val_loss: 0.0045\n",
      "Epoch 16/800\n",
      "69/70 [============================>.] - ETA: 0s - loss: 6.0117e-04Restoring model weights from the end of the best epoch.\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.0205e-04 - val_loss: 0.0045\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.8612e-04 - val_loss: 0.0045\n",
      "Epoch 2/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 6.8239e-04 - val_loss: 0.0045\n",
      "Epoch 3/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.8026e-04 - val_loss: 0.0045\n",
      "Epoch 4/800\n",
      "70/70 [==============================] - 3s 37ms/step - loss: 6.7878e-04 - val_loss: 0.0045\n",
      "Epoch 5/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.7672e-04 - val_loss: 0.0045\n",
      "Epoch 6/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.7442e-04 - val_loss: 0.0045\n",
      "Epoch 7/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.7265e-04 - val_loss: 0.0045\n",
      "Epoch 8/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.7101e-04 - val_loss: 0.0045\n",
      "Epoch 9/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.6934e-04 - val_loss: 0.0045\n",
      "Epoch 10/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.6797e-04 - val_loss: 0.0045\n",
      "Epoch 11/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.6665e-04 - val_loss: 0.0045\n",
      "Epoch 12/800\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.6511e-04 - val_loss: 0.0045\n",
      "Epoch 13/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.6366e-04 - val_loss: 0.0045\n",
      "Epoch 14/800\n",
      "70/70 [==============================] - 3s 40ms/step - loss: 6.6271e-04 - val_loss: 0.0045\n",
      "Epoch 15/800\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 6.6179e-04 - val_loss: 0.0045\n",
      "Epoch 16/800\n",
      "70/70 [==============================] - ETA: 0s - loss: 6.6013e-04Restoring model weights from the end of the best epoch.\n",
      "70/70 [==============================] - 3s 39ms/step - loss: 6.6013e-04 - val_loss: 0.0045\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x175569c70>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-5))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())\n",
    "model.compile(loss='MAE',optimizer=tf.keras.optimizers.Adam(1e-6))\n",
    "model.fit(X_train,y_train.T, epochs=800, batch_size=batch_size, verbose=1,validation_data=(X_val,y_val.T), callbacks=cus.callbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1570583e-05"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "metric = tf.keras.metrics.MeanSquaredError(name=\"mean_average_error\", dtype=None)\n",
    "metric.update_state(np.array(y_predicted),np.array(y_test.T))\n",
    "metric.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 1)\n",
      "(9999,)\n",
      "(9999,)\n"
     ]
    }
   ],
   "source": [
    "a = (y_predicted[:,0]-y_test)\n",
    "print(y_predicted.shape)\n",
    "print(y_test.shape)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating dataset\n",
    "print(a.shape)\n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a,bins=500,label=\"BOL\",color='g')\n",
    "plt.xlabel(\"$Δk_{\\infty}$\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.title(\"GODIVA $Δk_{\\infty}$, shaped serialization\")\n",
    "#plt.legend(loc='upper right')\n",
    "plt.xlim([-0.5,0.5])\n",
    "plt.ylim([0,1000])\n",
    "\n",
    "plt.savefig(\"/Volumes/data/LosAlamosSummer/All_Results/GODIVA/GODIVA_deltaK_fluxShaped12.png\",bbox_inches =\"tight\",\n",
    "            pad_inches = 1,\n",
    "            transparent = False,\n",
    "            facecolor =\"w\",\n",
    "            edgecolor ='w',\n",
    "            orientation ='landscape')\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06737911895538316\n",
      "0.0071792309360641715\n",
      "1.0796179340080996\n",
      "1.079447\n",
      "9999\n",
      "9999\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(np.std(y_test.T))\n",
    "print(np.std(a))\n",
    "print(np.mean(y_test.T))\n",
    "print(np.mean(y_predicted))\n",
    "print(len(y_test))\n",
    "print(len(y_predicted))\n",
    "print(len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    " \n",
    "\n",
    "n_bins = 500\n",
    " \n",
    "\n",
    "# Creating histogram\n",
    "fig, axs = plt.subplots(figsize =(10, 7))\n",
    " \n",
    "axs.hist(y_test.T*normConst, bins = n_bins,label=\"k-eigenvalues (ground truth))\")\n",
    "axs.hist(y_predicted*normConst, bins = n_bins,label=\"k-eigenvalues predicted\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"$k_{\\infty}$\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title(\"GODIVA $k_{\\infty}$, Shaped serialization \")\n",
    "plt.savefig(\"/Volumes/data/LosAlamosSummer/All_Results/GODIVA/kinfDist_fluxShaped_12.png\",bbox_inches =\"tight\",\n",
    "            pad_inches = 1,\n",
    "            transparent = False,\n",
    "            facecolor =\"w\",\n",
    "            edgecolor ='w',\n",
    "            orientation ='landscape')\n",
    "\n",
    "plt.show()\n",
    "# Show plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16c19f704522b294860ea2fcfcbccb05047b74a4c0e7a99ceb11e0c992f8aef7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tensorflow-groupstruct')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
